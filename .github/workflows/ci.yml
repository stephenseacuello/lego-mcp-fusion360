name: CI Pipeline

on:
  push:
    branches: [main, develop, release/*]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      run_e2e:
        description: 'Run E2E tests'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: "3.11"
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================
  # Code Quality & Linting
  # ============================================
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-

      - name: Install linters
        run: |
          pip install ruff black isort mypy bandit

      - name: Check formatting with Black
        run: black --check --diff shared/ dashboard/ tests/ || true

      - name: Check import sorting with isort
        run: isort --check-only --diff shared/ dashboard/ tests/ || true

      - name: Lint with Ruff
        run: ruff check shared/ dashboard/ tests/ --output-format=github || true

      - name: Type check with mypy
        run: mypy shared/ dashboard/ --ignore-missing-imports --no-error-summary || true

  # ============================================
  # Security Scanning (SAST)
  # ============================================
  security-sast:
    name: Security SAST
    runs-on: ubuntu-latest
    permissions:
      security-events: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: pip install bandit safety semgrep

      - name: Run Bandit security scan
        run: |
          bandit -r shared/ dashboard/ -f sarif -o bandit-results.sarif || true

      - name: Upload Bandit SARIF
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: bandit-results.sarif
          category: bandit
        continue-on-error: true

      - name: Check dependencies for vulnerabilities
        run: safety check -r requirements.txt --output json || true

      - name: Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/python
            p/security-audit
            p/secrets
        continue-on-error: true

  # ============================================
  # Unit Tests with Coverage
  # ============================================
  test:
    name: Unit Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: legomcp
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: legomcp_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov pytest-xdist hypothesis

      - name: Run unit tests with coverage
        env:
          DATABASE_URL: postgresql://legomcp:testpassword@localhost:5432/legomcp_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/ -v \
            --cov=dashboard --cov=shared \
            --cov-report=xml --cov-report=html \
            --cov-fail-under=10 \
            -n auto \
            --ignore=tests/e2e/ || true

      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests-py${{ matrix.python-version }}
          fail_ci_if_error: false

      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-py${{ matrix.python-version }}
          path: htmlcov/
          retention-days: 7

  # ============================================
  # Integration Tests
  # ============================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: legomcp
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: legomcp_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://legomcp:testpassword@localhost:5432/legomcp_test
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: test
        run: |
          pytest tests/integration/ -v --tb=short || true

  # ============================================
  # Build Docker Images
  # ============================================
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [lint, test]
    permissions:
      contents: read
      packages: write
    strategy:
      matrix:
        service: [dashboard, slicer-service, mcp-server]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}

      - name: Determine Dockerfile path
        id: dockerfile
        run: |
          if [ "${{ matrix.service }}" = "dashboard" ]; then
            echo "path=dashboard/Dockerfile" >> $GITHUB_OUTPUT
            echo "context=." >> $GITHUB_OUTPUT
          elif [ "${{ matrix.service }}" = "slicer-service" ]; then
            echo "path=slicer-service/Dockerfile" >> $GITHUB_OUTPUT
            echo "context=slicer-service" >> $GITHUB_OUTPUT
          else
            echo "path=mcp-server/Dockerfile" >> $GITHUB_OUTPUT
            echo "context=mcp-server" >> $GITHUB_OUTPUT
          fi

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ steps.dockerfile.outputs.context }}
          file: ${{ steps.dockerfile.outputs.path }}
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ github.ref_name }}

  # ============================================
  # Container Security Scanning
  # ============================================
  container-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    needs: [build-images]
    if: github.event_name != 'pull_request'
    permissions:
      security-events: write
    strategy:
      matrix:
        service: [dashboard, slicer-service]

    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: '${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.service }}:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results-${{ matrix.service }}.sarif'
          severity: 'CRITICAL,HIGH'
          vuln-type: 'os,library'
        continue-on-error: true

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results-${{ matrix.service }}.sarif'
          category: 'trivy-${{ matrix.service }}'
        continue-on-error: true

  # ============================================
  # Helm Chart Linting
  # ============================================
  helm-lint:
    name: Helm Chart Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Lint Helm chart
        run: |
          helm lint helm/legomcp/ || true

      - name: Template validation
        run: |
          helm template legomcp helm/legomcp/ \
            -f helm/legomcp/values.yaml \
            -f helm/legomcp/values-dev.yaml > /dev/null || true

  # ============================================
  # Kubernetes Manifest Validation
  # ============================================
  k8s-validate:
    name: K8s Manifest Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install kubeval
        run: |
          wget https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz
          tar xf kubeval-linux-amd64.tar.gz
          sudo mv kubeval /usr/local/bin/

      - name: Validate Kubernetes manifests
        run: |
          kubeval --strict k8s/base/*.yaml || true

      - name: Install kube-score
        run: |
          wget https://github.com/zegl/kube-score/releases/download/v1.18.0/kube-score_1.18.0_linux_amd64.tar.gz
          tar xf kube-score_1.18.0_linux_amd64.tar.gz
          sudo mv kube-score /usr/local/bin/

      - name: Score Kubernetes manifests
        run: |
          kube-score score k8s/base/*.yaml --output-format ci || true

  # ============================================
  # Performance Benchmarks
  # ============================================
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [test]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-benchmark

      - name: Run benchmarks
        run: |
          pytest benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-autosave || true

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30

      - name: Compare with baseline
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: false
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
        continue-on-error: true

  # ============================================
  # E2E Tests (Optional)
  # ============================================
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [build-images]
    if: github.event.inputs.run_e2e == 'true' || github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Compose
        run: |
          docker compose version

      - name: Start services
        run: |
          docker compose -f docker-compose.yml up -d
          sleep 30

      - name: Wait for services
        run: |
          timeout 120 bash -c 'until curl -s http://localhost:5000/health; do sleep 5; done' || true

      - name: Run E2E tests
        run: |
          pip install pytest httpx
          pytest tests/e2e/ -v --tb=short || true

      - name: Collect logs on failure
        if: failure()
        run: |
          docker compose logs > docker-compose-logs.txt

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-compose-logs
          path: docker-compose-logs.txt

      - name: Stop services
        if: always()
        run: docker compose down -v

  # ============================================
  # API Contract Tests
  # ============================================
  contract-tests:
    name: API Contract Tests
    runs-on: ubuntu-latest
    needs: [test]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install schemathesis httpx

      - name: Validate OpenAPI spec
        run: |
          if [ -f docs/openapi.yaml ]; then
            python -c "import yaml; yaml.safe_load(open('docs/openapi.yaml'))"
          fi

      - name: Run contract tests
        run: |
          if [ -f docs/openapi.yaml ]; then
            schemathesis run docs/openapi.yaml --dry-run || true
          fi

  # ============================================
  # Documentation Build
  # ============================================
  docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install documentation tools
        run: pip install mkdocs mkdocs-material mkdocstrings[python]

      - name: Build documentation
        run: |
          if [ -f mkdocs.yml ]; then
            mkdocs build --strict
          fi
        continue-on-error: true

  # ============================================
  # Notification
  # ============================================
  notify:
    name: Notify
    runs-on: ubuntu-latest
    needs: [lint, test, security-sast, build-images]
    if: always()
    steps:
      - name: Determine status
        id: status
        run: |
          if [ "${{ needs.test.result }}" == "failure" ] || \
             [ "${{ needs.build-images.result }}" == "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
          else
            echo "status=success" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack notification
        if: github.ref == 'refs/heads/main' && steps.status.outputs.status == 'failure'
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "text": "CI Pipeline Failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*CI Pipeline Failed* :x:\n*Repository:* ${{ github.repository }}\n*Branch:* ${{ github.ref_name }}\n*Commit:* ${{ github.sha }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        continue-on-error: true
