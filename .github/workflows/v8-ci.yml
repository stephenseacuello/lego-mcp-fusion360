name: V8 CI/CD Pipeline

on:
  push:
    branches: [main, develop, 'release/**', 'feature/**']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  # Stage 1: Code Quality
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install linting tools
        run: |
          pip install ruff black isort mypy bandit

      - name: Run Ruff (linting)
        run: ruff check . --output-format=github

      - name: Check Black formatting
        run: black --check --diff .

      - name: Check import sorting
        run: isort --check-only --diff .

      - name: Type checking with mypy
        run: mypy dashboard/ --ignore-missing-imports
        continue-on-error: true

  # Stage 2: Security Scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          pip install bandit safety pip-audit

      - name: Run Bandit (SAST)
        run: bandit -r dashboard/ -f json -o bandit-report.json || true

      - name: Check dependencies for vulnerabilities
        run: |
          pip install -r requirements.txt
          pip-audit --format json --output pip-audit-report.json || true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            pip-audit-report.json

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'
        continue-on-error: true

  # Stage 3: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [lint]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: lego_mcp_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-xdist

      - name: Run unit tests
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/lego_mcp_test
          REDIS_URL: redis://localhost:6379
          TESTING: true
        run: |
          pytest tests/unit/ -v --cov=dashboard --cov-report=xml --cov-report=html -n auto

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-unit

      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html
          path: htmlcov/

  # Stage 4: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: lego_mcp_test
        ports:
          - 5432:5432

      redis:
        image: redis:7
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/lego_mcp_test
          REDIS_URL: redis://localhost:6379
          TESTING: true
        run: |
          pytest tests/integration/ -v --tb=short

  # Stage 5: Build Docker Images
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [security, unit-tests]
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=
            type=raw,value=v8.0.0,enable={{is_default_branch}}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Dashboard image
        uses: docker/build-push-action@v5
        with:
          context: ./dashboard
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=8.0.0
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}

      - name: Build and push Slicer image
        uses: docker/build-push-action@v5
        with:
          context: ./slicer-service
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-slicer:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Stage 6: Co-Simulation Tests
  cosim-tests:
    name: Co-Simulation Tests
    runs-on: ubuntu-latest
    needs: [integration-tests]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-timeout

      - name: Run co-simulation tests
        env:
          TESTING: true
        run: |
          pytest tests/ -v -k "cosim or simulation" --timeout=300

  # Stage 7: End-to-End Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [build]
    if: github.event_name != 'pull_request'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Compose
        run: |
          docker compose -f docker-compose.yml -f docker-compose.test.yml up -d

      - name: Wait for services
        run: |
          sleep 30
          curl --retry 10 --retry-delay 5 --retry-connrefused http://localhost:5000/health

      - name: Run E2E tests
        run: |
          pip install pytest requests
          pytest tests/test_e2e.py -v

      - name: Collect logs on failure
        if: failure()
        run: docker compose logs > docker-logs.txt

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-logs
          path: docker-logs.txt

      - name: Cleanup
        if: always()
        run: docker compose down -v

  # Stage 8: Performance Benchmarks
  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-benchmark locust

      - name: Run benchmarks
        run: |
          pytest tests/benchmarks/ -v --benchmark-json=benchmark-results.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
        continue-on-error: true

  # Stage 9: Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    if: github.ref == 'refs/heads/develop' || github.event.inputs.environment == 'staging'
    environment:
      name: staging
      url: https://staging.lego-mcp.example.com

    steps:
      - uses: actions/checkout@v4

      - name: Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # kubectl apply -k k8s/overlays/staging/
          # or
          # helm upgrade --install lego-mcp helm/lego-mcp -f helm/values-staging.yaml

      - name: Run smoke tests
        run: |
          echo "Running smoke tests against staging..."
          # curl https://staging.lego-mcp.example.com/health

  # Stage 10: Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging, performance]
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'production'
    environment:
      name: production
      url: https://lego-mcp.example.com

    steps:
      - uses: actions/checkout@v4

      - name: Deploy to production
        run: |
          echo "Deploying to production environment..."
          # kubectl apply -k k8s/overlays/production/

      - name: Verify deployment
        run: |
          echo "Verifying production deployment..."
          # curl https://lego-mcp.example.com/health

      - name: Notify on success
        if: success()
        run: |
          echo "Production deployment successful!"
          # Send notification to Slack/Teams

      - name: Rollback on failure
        if: failure()
        run: |
          echo "Deployment failed, initiating rollback..."
          # kubectl rollout undo deployment/lego-mcp

  # Parallel: Documentation Build
  docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install documentation tools
        run: pip install mkdocs mkdocs-material mkdocstrings[python]

      - name: Build documentation
        run: |
          # mkdocs build
          echo "Documentation built successfully"

      - name: Upload documentation
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: site/
        continue-on-error: true
