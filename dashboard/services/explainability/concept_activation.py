"""
Testing with Concept Activation Vectors (TCAV).

LEGO MCP v6.0 World-Class Manufacturing Research Platform
Phase 2: Causal AI & Explainability Engine

Provides concept-based explanations for deep learning models using TCAV.
TCAV enables understanding what high-level concepts a model has learned.
"""

from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Tuple, Callable
from datetime import datetime
from enum import Enum
import logging
import uuid
import math
import random

logger = logging.getLogger(__name__)


class ConceptType(Enum):
    """Types of manufacturing concepts."""
    SURFACE_QUALITY = "surface_quality"
    LAYER_ADHESION = "layer_adhesion"
    DIMENSIONAL_ACCURACY = "dimensional_accuracy"
    COLOR_CONSISTENCY = "color_consistency"
    STRUCTURAL_INTEGRITY = "structural_integrity"
    PRINT_DEFECT = "print_defect"
    MATERIAL_PROPERTY = "material_property"
    GEOMETRIC_FEATURE = "geometric_feature"


@dataclass
class Concept:
    """A high-level concept for TCAV analysis."""
    concept_id: str
    name: str
    concept_type: ConceptType
    description: str
    positive_examples: List[str]  # Paths to positive example images
    negative_examples: List[str]  # Paths to negative/random examples
    created_at: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "concept_id": self.concept_id,
            "name": self.name,
            "concept_type": self.concept_type.value,
            "description": self.description,
            "positive_count": len(self.positive_examples),
            "negative_count": len(self.negative_examples),
            "created_at": self.created_at.isoformat(),
            "metadata": self.metadata,
        }


@dataclass
class ConceptActivationVector:
    """A trained Concept Activation Vector (CAV)."""
    cav_id: str
    concept_id: str
    layer_name: str
    direction: List[float]  # The CAV direction in activation space
    accuracy: float  # Linear classifier accuracy
    created_at: datetime

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "cav_id": self.cav_id,
            "concept_id": self.concept_id,
            "layer_name": self.layer_name,
            "accuracy": self.accuracy,
            "direction_dim": len(self.direction),
            "created_at": self.created_at.isoformat(),
        }


@dataclass
class TCAVScore:
    """TCAV score for a concept-class pair."""
    concept_id: str
    concept_name: str
    target_class: str
    layer_name: str
    tcav_score: float  # Fraction of class examples with positive directional derivative
    statistical_significance: float  # p-value from permutation test
    is_significant: bool
    confidence_interval: Tuple[float, float]

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "concept_id": self.concept_id,
            "concept_name": self.concept_name,
            "target_class": self.target_class,
            "layer_name": self.layer_name,
            "tcav_score": self.tcav_score,
            "statistical_significance": self.statistical_significance,
            "is_significant": self.is_significant,
            "confidence_interval": self.confidence_interval,
        }


class ConceptActivationTester:
    """
    TCAV (Testing with Concept Activation Vectors) implementation.

    TCAV answers: "Is concept C important for predicting class K?"

    For LEGO manufacturing:
    - Is "surface roughness" important for predicting "defective"?
    - Is "layer adhesion" important for predicting "high quality"?
    - Is "warping" important for predicting "failed print"?

    Reference: Kim et al. "Interpretability Beyond Feature Attribution:
               Quantitative Testing with Concept Activation Vectors (TCAV)"
    """

    def __init__(
        self,
        model_name: str = "quality_classifier",
        layers_to_test: Optional[List[str]] = None,
    ):
        self.model_name = model_name
        self.layers_to_test = layers_to_test or [
            "layer3",  # Mid-level features
            "layer4",  # High-level features
            "avgpool",  # Pre-classifier
        ]
        self.concepts: Dict[str, Concept] = {}
        self.cavs: Dict[str, ConceptActivationVector] = {}
        self._initialize_default_concepts()

    def _initialize_default_concepts(self):
        """Initialize default manufacturing concepts."""
        default_concepts = [
            Concept(
                concept_id="concept-surface-smooth",
                name="Smooth Surface",
                concept_type=ConceptType.SURFACE_QUALITY,
                description="Parts with smooth, uniform surface finish",
                positive_examples=["/data/concepts/smooth_surface/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-surface-rough",
                name="Rough Surface",
                concept_type=ConceptType.SURFACE_QUALITY,
                description="Parts with visible layer lines or roughness",
                positive_examples=["/data/concepts/rough_surface/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-warping",
                name="Warping",
                concept_type=ConceptType.PRINT_DEFECT,
                description="Parts showing warping or curling at edges",
                positive_examples=["/data/concepts/warping/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-stringing",
                name="Stringing",
                concept_type=ConceptType.PRINT_DEFECT,
                description="Parts with string-like artifacts between features",
                positive_examples=["/data/concepts/stringing/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-layer-separation",
                name="Layer Separation",
                concept_type=ConceptType.LAYER_ADHESION,
                description="Parts with visible gaps between layers",
                positive_examples=["/data/concepts/layer_separation/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-good-adhesion",
                name="Good Layer Adhesion",
                concept_type=ConceptType.LAYER_ADHESION,
                description="Parts with strong inter-layer bonding",
                positive_examples=["/data/concepts/good_adhesion/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
            Concept(
                concept_id="concept-stud-quality",
                name="LEGO Stud Quality",
                concept_type=ConceptType.GEOMETRIC_FEATURE,
                description="Well-formed LEGO studs with correct dimensions",
                positive_examples=["/data/concepts/good_studs/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
                metadata={"lego_specific": True},
            ),
            Concept(
                concept_id="concept-color-uniform",
                name="Uniform Color",
                concept_type=ConceptType.COLOR_CONSISTENCY,
                description="Parts with consistent color throughout",
                positive_examples=["/data/concepts/uniform_color/*.png"],
                negative_examples=["/data/concepts/random/*.png"],
                created_at=datetime.now(),
            ),
        ]

        for concept in default_concepts:
            self.concepts[concept.concept_id] = concept

    def add_concept(
        self,
        name: str,
        concept_type: ConceptType,
        description: str,
        positive_examples: List[str],
        negative_examples: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Concept:
        """Add a new concept for TCAV testing."""
        concept_id = f"concept-{name.lower().replace(' ', '-')}-{uuid.uuid4().hex[:6]}"

        concept = Concept(
            concept_id=concept_id,
            name=name,
            concept_type=concept_type,
            description=description,
            positive_examples=positive_examples,
            negative_examples=negative_examples or ["/data/concepts/random/*.png"],
            created_at=datetime.now(),
            metadata=metadata or {},
        )

        self.concepts[concept_id] = concept
        logger.info(f"Added concept: {name}")

        return concept

    def train_cav(
        self,
        concept_id: str,
        layer_name: str,
    ) -> ConceptActivationVector:
        """
        Train a CAV for a concept at a specific layer.

        In production, this would:
        1. Extract activations for positive examples at the layer
        2. Extract activations for negative examples at the layer
        3. Train a linear classifier (SVM or logistic regression)
        4. The CAV is the normal to the decision boundary
        """
        if concept_id not in self.concepts:
            raise ValueError(f"Concept not found: {concept_id}")

        concept = self.concepts[concept_id]

        # Simulate CAV training
        # In production: Train linear classifier on activations
        activation_dim = 512  # Typical CNN feature dimension
        direction = [random.gauss(0, 1) for _ in range(activation_dim)]

        # Normalize to unit vector
        norm = math.sqrt(sum(d ** 2 for d in direction))
        direction = [d / norm for d in direction]

        # Simulate classifier accuracy (0.5 = random, 1.0 = perfect)
        accuracy = 0.75 + random.uniform(0, 0.2)

        cav = ConceptActivationVector(
            cav_id=f"cav-{uuid.uuid4().hex[:8]}",
            concept_id=concept_id,
            layer_name=layer_name,
            direction=direction,
            accuracy=accuracy,
            created_at=datetime.now(),
        )

        self.cavs[f"{concept_id}_{layer_name}"] = cav
        logger.info(f"Trained CAV for {concept.name} at {layer_name}, accuracy={accuracy:.3f}")

        return cav

    def compute_tcav_score(
        self,
        concept_id: str,
        target_class: str,
        layer_name: str,
        num_permutations: int = 30,
    ) -> TCAVScore:
        """
        Compute TCAV score for a concept-class pair.

        TCAV score = fraction of class examples where directional derivative
                     along CAV direction is positive.

        A TCAV score > 0.5 indicates the concept positively influences
        the class prediction.
        """
        cav_key = f"{concept_id}_{layer_name}"

        # Train CAV if not already trained
        if cav_key not in self.cavs:
            self.train_cav(concept_id, layer_name)

        concept = self.concepts[concept_id]

        # Simulate TCAV score computation
        # In production:
        # 1. Get all examples of target_class
        # 2. For each example, compute gradient of class logit w.r.t. layer activations
        # 3. Compute directional derivative (dot product with CAV)
        # 4. Count fraction with positive directional derivative

        # Simulate meaningful scores based on concept-class relationships
        tcav_base = self._get_expected_tcav_score(concept.name, target_class)
        tcav_score = tcav_base + random.uniform(-0.1, 0.1)
        tcav_score = max(0.0, min(1.0, tcav_score))

        # Statistical significance via permutation test
        # Simulate p-value
        if abs(tcav_score - 0.5) > 0.15:
            p_value = random.uniform(0.001, 0.05)
        else:
            p_value = random.uniform(0.1, 0.5)

        # Confidence interval (approximate)
        margin = 0.1
        ci_low = max(0, tcav_score - margin)
        ci_high = min(1, tcav_score + margin)

        result = TCAVScore(
            concept_id=concept_id,
            concept_name=concept.name,
            target_class=target_class,
            layer_name=layer_name,
            tcav_score=round(tcav_score, 3),
            statistical_significance=round(p_value, 4),
            is_significant=p_value < 0.05,
            confidence_interval=(round(ci_low, 3), round(ci_high, 3)),
        )

        logger.info(
            f"TCAV score for '{concept.name}' â†’ '{target_class}': "
            f"{tcav_score:.3f} (p={p_value:.4f})"
        )

        return result

    def _get_expected_tcav_score(self, concept_name: str, target_class: str) -> float:
        """Get expected TCAV score based on domain knowledge."""
        # Define expected relationships
        positive_relationships = {
            ("Smooth Surface", "high_quality"): 0.85,
            ("Good Layer Adhesion", "high_quality"): 0.82,
            ("LEGO Stud Quality", "high_quality"): 0.88,
            ("Uniform Color", "high_quality"): 0.75,
            ("Warping", "defective"): 0.90,
            ("Stringing", "defective"): 0.78,
            ("Layer Separation", "defective"): 0.92,
            ("Rough Surface", "defective"): 0.70,
        }

        key = (concept_name, target_class)
        if key in positive_relationships:
            return positive_relationships[key]

        # Default neutral score
        return 0.5

    def run_tcav_analysis(
        self,
        target_class: str,
        concept_ids: Optional[List[str]] = None,
        layers: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        Run complete TCAV analysis for a target class.

        Returns scores for all concepts across all layers.
        """
        concepts_to_test = concept_ids or list(self.concepts.keys())
        layers_to_test = layers or self.layers_to_test

        results = {
            "target_class": target_class,
            "model": self.model_name,
            "analysis_id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "scores": [],
            "summary": {},
        }

        for layer in layers_to_test:
            layer_scores = []

            for concept_id in concepts_to_test:
                score = self.compute_tcav_score(concept_id, target_class, layer)
                layer_scores.append(score.to_dict())

            results["scores"].extend(layer_scores)

        # Generate summary
        significant_positive = [
            s for s in results["scores"]
            if s["is_significant"] and s["tcav_score"] > 0.6
        ]
        significant_negative = [
            s for s in results["scores"]
            if s["is_significant"] and s["tcav_score"] < 0.4
        ]

        results["summary"] = {
            "total_tests": len(results["scores"]),
            "significant_results": len(significant_positive) + len(significant_negative),
            "top_positive_concepts": sorted(
                significant_positive,
                key=lambda x: x["tcav_score"],
                reverse=True
            )[:5],
            "top_negative_concepts": sorted(
                significant_negative,
                key=lambda x: x["tcav_score"]
            )[:5],
        }

        return results

    def explain_prediction(
        self,
        image_path: str,
        predicted_class: str,
    ) -> Dict[str, Any]:
        """
        Generate concept-based explanation for a single prediction.

        "This brick was classified as 'defective' because it exhibits
        high activation for 'Warping' (TCAV=0.9) and 'Layer Separation' (TCAV=0.85)."
        """
        # Run TCAV for the predicted class
        tcav_results = self.run_tcav_analysis(predicted_class)

        # Get most influential concepts
        significant = [
            s for s in tcav_results["scores"]
            if s["is_significant"]
        ]

        top_concepts = sorted(
            significant,
            key=lambda x: abs(x["tcav_score"] - 0.5),
            reverse=True
        )[:5]

        # Generate natural language explanation
        explanation_parts = []
        for concept in top_concepts:
            direction = "exhibits" if concept["tcav_score"] > 0.5 else "lacks"
            strength = "strongly" if abs(concept["tcav_score"] - 0.5) > 0.3 else "moderately"
            explanation_parts.append(
                f"{strength} {direction} '{concept['concept_name']}' "
                f"(TCAV={concept['tcav_score']:.2f})"
            )

        explanation = (
            f"This part was classified as '{predicted_class}' because it "
            + ", and ".join(explanation_parts[:3]) + "."
        )

        return {
            "image_path": image_path,
            "predicted_class": predicted_class,
            "explanation": explanation,
            "concept_scores": top_concepts,
            "confidence_note": (
                "Note: Concepts with TCAV > 0.5 positively contribute to this "
                "prediction, while TCAV < 0.5 indicates the concept works against it."
            ),
        }

    def get_concept_bottleneck(
        self,
        target_classes: List[str],
    ) -> Dict[str, Any]:
        """
        Identify which concepts are bottlenecks for each class.

        A concept is a bottleneck if it's highly predictive of a class.
        """
        bottlenecks = {}

        for target_class in target_classes:
            analysis = self.run_tcav_analysis(target_class)

            # Find concepts that strongly predict this class
            strong_predictors = [
                s for s in analysis["scores"]
                if s["is_significant"] and s["tcav_score"] > 0.7
            ]

            bottlenecks[target_class] = {
                "concepts": [s["concept_name"] for s in strong_predictors],
                "scores": strong_predictors,
            }

        return {
            "bottleneck_analysis": bottlenecks,
            "recommendation": self._generate_bottleneck_recommendations(bottlenecks),
        }

    def _generate_bottleneck_recommendations(
        self,
        bottlenecks: Dict[str, Any],
    ) -> List[str]:
        """Generate actionable recommendations from bottleneck analysis."""
        recommendations = []

        for class_name, data in bottlenecks.items():
            concepts = data["concepts"]

            if class_name == "defective" and concepts:
                recommendations.append(
                    f"To reduce '{class_name}' predictions, focus on mitigating: "
                    + ", ".join(concepts[:3])
                )
            elif class_name == "high_quality" and concepts:
                recommendations.append(
                    f"To increase '{class_name}' predictions, enhance: "
                    + ", ".join(concepts[:3])
                )

        return recommendations

    def list_concepts(self) -> List[Dict[str, Any]]:
        """List all available concepts."""
        return [c.to_dict() for c in self.concepts.values()]

    def get_concept(self, concept_id: str) -> Optional[Concept]:
        """Get a concept by ID."""
        return self.concepts.get(concept_id)
